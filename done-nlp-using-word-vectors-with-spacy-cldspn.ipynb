{"cells":[{"metadata":{"_cell_guid":"109a529b-0cab-4b94-8946-0a92a22e64b8","_uuid":"cc4a1755ea8cc9ef3d822bf8bcb94f54cb7365af"},"cell_type":"markdown","source":"# NLP using Word Vectors with Spacy \n\n## [Central London Data Science Project Nights](https://www.meetup.com/central_london_data_science/)\n\nThis notebook will show you how to ustilise word vectors using spacy and how they can be used in creating and \"What to read next...\" system.\n\n[Spacy](https://spacy.io/) is a production grade open source NLP library that includes word vectors!\n\n**TASK** : start off by running the cell below to load in the libraries"},{"metadata":{"_cell_guid":"47f8e988-bfa6-4a63-ac57-850ae1279ad8","_uuid":"a901570365068bea693743924b3e13c3b703e1eb","collapsed":true,"trusted":true},"cell_type":"code","source":"import spacy \n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# this line makes any plots display in the notebook\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"c5a8dec3-7f77-49d0-9a26-0ae3e78c3b3a","_uuid":"510748d89e58c04b87fb90d88025e4635e037b80"},"cell_type":"markdown","source":"**TASK** : load the word vectors by running :\n\n```python\nnlp = spacy.load('en_core_web_lg')\n```\n\nYou can see [here](https://spacy.io/models/en#en_core_web_lg) that this model contains 685,000 unique word vectors!!"},{"metadata":{"_cell_guid":"f2861504-3784-4b4f-88e9-936b5a1720f1","_uuid":"7bb7028d041ede789fd54eb6c9e56f09ce814415","collapsed":true,"trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nnlp = spacy.load('en_core_web_lg')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"2f1896d8-f08f-4444-acd4-2c23a69bc2c3","_uuid":"aea8a337dca7b9ce801ed432e47db4d4633e4e2a"},"cell_type":"markdown","source":"## Let's get comfortable with a single word vector"},{"metadata":{"_cell_guid":"7d0cb420-d1d5-4da1-9fff-f1636130f4ae","_uuid":"3dedb2024ac6931b334fbe707d80aaf10562a9b6"},"cell_type":"markdown","source":"**TASK** : get the vector of any word by running:\n```python\nnlp('dog').vector\n```"},{"metadata":{"scrolled":false,"_cell_guid":"61dc0450-8ce4-4fbf-85fd-5a0767fae61d","_uuid":"80184a60b718c0b8bab141bf0135d02b4700424a","trusted":true},"cell_type":"code","source":"# YORU CODE GOES HERE\n\nnlp('dog').vector","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"83a793bf-f8af-4ba9-881b-7472194e6b89","_uuid":"5f13f3444bec6e83e2c24994eec616c239943c34"},"cell_type":"markdown","source":"looks like a lot of numbers, view the number of dimensions by using the `.shape` on a vector:\n\n**the output should look like this**:\n\n```python\n(300,)\n```"},{"metadata":{"_cell_guid":"35f0910c-2441-4e06-80d9-219fc8a312c5","_uuid":"e4e5c7ebc91bf79b7aea2ab0a936f9b7b61ab78f","trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nnlp('dog').vector.shape","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"e8028b1d-9289-49be-b9e9-33e47b77a7fe","_uuid":"529edacbf2d047a9f405ccb7e62ceab11a9578e6"},"cell_type":"markdown","source":"**TASK** : lets visualise the vector values in a bar plot:\n\n```python\nplt.bar(range(NUMBER_OF_DIMENSIONS), YOUR_VECTOR)\nplt.show()\n```\n\nWhen you have done that, play around with different words to see how they differ on the bar plot:"},{"metadata":{"_cell_guid":"dc78409e-780e-4e6a-ae25-5ad23f02e8f1","_uuid":"a0e0401fc58db500b9a36aa314e397bf4f3c0c33","trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nplt.bar(range(300), nlp('dog').vector)\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"2d7bb583-3e0a-47c5-be32-a3c8dfd59d83","_uuid":"8d81bb1d0dafa769b70943a2226db241189104df"},"cell_type":"markdown","source":"---\n\n## Let's now do some word comparisons"},{"metadata":{"_cell_guid":"83baeeb2-aa18-4d0c-adaa-7a92344ebd1f","_uuid":"9205b94d725d8569ce9c3c6065b59c91604c1350"},"cell_type":"markdown","source":"**TASK** : Create a varible called `cat` and assign it the vector for `\"cat\"`, and create a varible called `dog` and assign it the vector for `\"dog\"`:"},{"metadata":{"_cell_guid":"7a66f006-08eb-4f99-84a7-6eb4f5e3cd97","_uuid":"152c0e265089d2ebedca0b3762fb33c08b69d058","collapsed":true,"trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\ncat = nlp('cat').vector\ndog = nlp('dog').vector","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"4ed6538b-0e1a-43d5-8f1f-1cb7cff0ed6d","_uuid":"14d285220dc1b4da27e99e1b05956307823b58db"},"cell_type":"markdown","source":"### How to compare vectors\n\n**HEADS UP**- Don't worry if your not comfortable with the following maths, You won't need to fully understand it to progress, it's just a bit of extra background knowledge ðŸ˜Ž\n\nOn of the most common ways of comparing vectors is using [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n\nCosine similarity is a measure focusing on the angle between 2 vectors, if the the angle is small -> the cosine will be high and therefore they are similare vectors, if the angle is large -> the cosine will be small and therefore : they are very different vectors: \n\n![cosine](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/cosine_similarity.png)\n\nhttp://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/\n\nIt's calculated with the following equation :\n\n![cosine equation](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/cosine1.png)\n\nWe can do this in raw numpy with the following code:\n\n```python\nnp.dot(VECTOR_1, VECTOR_2) / (np.linalg.norm(VECTOR_1) * np.linalg.norm(VECTOR_2))\n```\n\n**TASK** : Calculate the cosine similarity between your `dog` vector and your `cat` vector:\n\nYour answer should be close to `0.801685`"},{"metadata":{"_cell_guid":"f19ee7ff-9d35-4ec4-8a37-753f95d6a3bf","_uuid":"fdb728e7cdee0ee67d59ae0705b625daeb33bef8","trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nnp.dot(dog, cat) / (np.linalg.norm(dog) * np.linalg.norm(cat))","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"bd9f482d-1df6-494b-86c4-2e69599ab09d","_uuid":"c73684070a212a3a7d6e050368a0623095146ee2"},"cell_type":"markdown","source":"Ofcourse there are libraries that can do this for your!\n\n**TASK** : import the `cosine` function from the `scipy` package with the following import statement:\n\n```python\nfrom scipy.spatial.distance import cosine\n```"},{"metadata":{"_cell_guid":"cd574ca6-9ec9-46fa-9aa6-584c1e2129d7","_uuid":"8780e9301871e94f8c99d8dc0c1ba90c91a9d740","collapsed":true,"trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nfrom scipy.spatial.distance import cosine","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"3b5c9943-4187-4236-92fe-95efa036989c","_uuid":"5d9615a17e5723881e1c7afab7261540fd00abc9"},"cell_type":"markdown","source":"**TASK** : Calulate the similarity between the dog and cat vectors like before using the `cosine` funnction\n\n**NOTE** : The `cosine` function you have imported will return the [*cosine distance*](https://en.wikipedia.org/wiki/Cosine_similarity#Angular_distance_and_similarity), to get the *cosine similarity* we just do the following:\n\n```python\n1 - cosine(VECTOR_1, VECTOR_2)\n```\n\nsame as before, your answer should be close to `0.801685`"},{"metadata":{"_cell_guid":"79b3a5c1-b7e3-4327-bec2-000941c65893","_uuid":"2044fea8518e3ecb3accda81ae6dba5feed7e078","trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\n1 - cosine(cat, dog)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"4f714bac-a1cc-4e05-b2cc-81809e35dd6d","_uuid":"557a02641f302f877db696815bc12b12373473ad"},"cell_type":"markdown","source":"### Even easier! Spacy has it built in!\n\nSpacy will do this for you using `.similarity` on an nlp object:\n\n```python\nnlp('car').similarity(nlp('bike'))\n```\n\n**TASK** : Get the similarity between `'dog'` and `'cat'` using spacy's `.similarity` function:\n\nsame as before, your answer should be close to `0.801685`"},{"metadata":{"_cell_guid":"368f7f75-402c-4c06-813b-ec6d1390c940","_uuid":"99b2ee8d1eb231e9b412f440627487c473173da4","trusted":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nnlp('cat').similarity(nlp('dog'))","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"50f03327-f5d9-4e89-9c65-2129e7785ed1","_uuid":"186a2e3bb4b6ca200192ba37d82c6ad3aabe6bba"},"cell_type":"markdown","source":"Below is a list of words\n\n**TASK** : print out how similiar each word is to `'cat'` in order to help you find out which is the best replacement pet:\n\nCheck the completed notebook if your get stuck"},{"metadata":{"_cell_guid":"9b18e498-dd9a-423e-850b-9352379d5db2","_uuid":"ac2bb4566f992e1d600586b31500edd934cf18b3","trusted":true},"cell_type":"code","source":"words = ['car', 'truck', 'dragon', 'data', 'horse', 'fish' , 'lion']\n\n#YOUR CODE GOES HERE\n\nfor word in words:\n    print(word, nlp('cat').similarity(nlp(word)))","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"05f4dada-5826-457d-be2d-c9219516646f","_uuid":"e4a0e513c570ddc003cf256f440a9b52917b1d95"},"cell_type":"markdown","source":"---\n\n## Onwards to document vectors!"},{"metadata":{"_cell_guid":"6e814119-c7fd-4b62-864e-0744a04f9d63","_uuid":"c83e6258ef6fd6ba39f07c9a1b571c4e802a6f6f"},"cell_type":"markdown","source":"The simplest way to generate a document vector is just to get the average word vector in that document.\n\nYou can do this using the techniques you've learnt previously using standard python loops and simple numpy operations e.g adding vectors using `+` and dividing using `/`.\n\n**TASK** : Calculate the average word vector of the sentence `'why is the cat on the boat'` below. (I've provided a few bits of code to help)\n\nThe `.sum()` of the document vector should around `-0.8358`\n\nCheck the completed noetbook if you get stuck"},{"metadata":{"_cell_guid":"a2b54dbe-349d-483c-8024-c2261a582126","_uuid":"1681eb7d8a809cd8187dfcba40abca0797e39f07","trusted":true},"cell_type":"code","source":"sentence = 'why is the cat on the boat'\n\n# numpy array with the dimensions (300,), filled with zeros\ntotal = np.zeros(300)\n\n# words from the text split into a list\nwords = sentence.split(' ')\n\n# number of words in the sentence\nn = len(words)\n\n# the variable that the average word vector should be stored in \naverage = None\n\n\n# YOUR CODE GOES HERE\n\nfor word in words:\n    word_vec = nlp(word).vector\n    total += word_vec\n\naverage = total / n\n\n# YOUR CODE ENDS HERE\n\nif average is not None:\n    print(average.sum())\n","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"d89bf1d5-5617-473d-b6e3-e3d3f1174132","_uuid":"1754379234e60fdef5919aa839ef1e33a73042a0"},"cell_type":"markdown","source":"### How you can do the same thing a bit quicker:\n\n```python\n# use list comprehension to get the vectors for each word\nword_vector_list = [nlp(word).vector for word in sentence.split(' ')]\n\n# calculate the mean across each word\naverage_word_vector = np.mean(word_vector_list, axis=0)\n\n# check that the sum is the same as the other way\nprint(average_word_vector.sum())\n```\n\n**TASK** : Copy and past the above code to check it gets a similar result as the previous task (should around `-0.8358`):"},{"metadata":{"_cell_guid":"1f3d7e5a-af18-4cc4-947f-e2451bc28f1b","_uuid":"9ea4d7f33428079b10d98a498637966bc4a761d0","trusted":false,"collapsed":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\n# use list comprehension to get the vectors for each word\nword_vector_list = [nlp(word).vector for word in sentence.split(' ')]\n\n# covert that list to a numpy array and calculate the mean across each word\naverage_word_vector = np.mean(word_vector_list, axis=0)\n\n# check that the sum is the same as the other way\nprint(average_word_vector.sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"848d3ee4-a3e1-4456-94ee-5a9637391119","_uuid":"39c59197b32a674a2bff2d0a6362ee45a82665fd"},"cell_type":"markdown","source":"### Spacy to the rescue! again!\n\nSpacy will already do this average word vector calculation for you:\n\n```python\nnlp('what ever you want to say').vector\n```\n\n**TASK** : Do this for the sentence you used previously and check the sum is similare (should around `-0.8358`):"},{"metadata":{"_cell_guid":"fca1d5af-b762-4ee4-8a79-98d690f06eff","_uuid":"97f9ac2792909dc93bb1e58ec89a263b9fecfbf6","trusted":false,"collapsed":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nnlp(sentence).vector.sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"631db560-ebe5-447e-b946-84dddffe181f","_uuid":"96808a20dcb41dedb0d3a6db9c626cf5bf0bc254"},"cell_type":"markdown","source":"Like how you've already done it with words, find out which of the following sentences is most similar to the sentence `'why is my cat on the car'`:\n\n**TASK** : print out the similarity score for each sentence against the `sentence_to_compare` to help you see which one is most similar:"},{"metadata":{"_cell_guid":"98a4daa9-7c70-439d-aa53-681286e67a26","_uuid":"b769c0f50af1c1b0eb1c025b65934b677c95e8a1","trusted":false,"collapsed":true},"cell_type":"code","source":"sentence_to_compare = 'why is my cat on the car'\n\nsentences = [\"where did my dog go\", \n             \"dude where's my car\",\n             \"i've lost my cat in the car\",\n             \"get that boat back\",\n             \"find my cat\",\n             \"why is my dog on the drugs\"]\n\n# YOURE CODE GOES HERE\n\nfor sentence in sentences:\n    sim = nlp(sentence_to_compare).similarity(nlp(sentence))\n    print(sentence,'-', sim)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"38e02e45-5c81-4f3f-bf10-73a7bc33e3d6","_uuid":"cebb9558b5899eb552cf8acdb630464c2d63e830"},"cell_type":"markdown","source":"Let's improve our sentence similarity system by removing stop words i.e very common words that carry little meaning. \n\nBelow we have created the function `remove_stop_words()` which will remove stop words from text passed to it e.g:\n\n```python\nremove_stop_words('why is my dog on the drugs')\n>> 'dog drugs'\n```\n\n**TASK** : Using this function, do the same task as before (print out the similarity score for each sentence against the sentence_to_compare to help you see which one is most similar) but remove the stop words when your doing it."},{"metadata":{"_cell_guid":"fbd16f23-c485-40b8-ac90-b1b918250b52","_uuid":"4f3eccc7a85d4ef5b5b95d6a4c760ffdf20d3711","trusted":false,"collapsed":true},"cell_type":"code","source":"# import the list of stop words from the spacy library\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\ndef remove_stop_words(text):\n    return ' '.join([word for word in text.split(' ') if word.lower() not in STOP_WORDS])\n\n\n# YOUR CODE GOES HERE\n\nfor sentence in sentences:\n    sim = nlp(remove_stop_words(sentence_to_compare)).similarity(nlp(remove_stop_words(sentence)))\n    print(sentence,'-', sim)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"458c3ffc-4070-4eca-b1de-accd9451928c","_uuid":"7331912db7f35f4ce04f9b69355fabb59195f5f0"},"cell_type":"markdown","source":"---\n\n## Alrighty let's visualise some word vectors! (task free section)"},{"metadata":{"_cell_guid":"c3029ba9-4862-4048-b633-883da8ee96cd","_uuid":"06ef49da7097124f9a905692f4d789e2444e0d70"},"cell_type":"markdown","source":"Visulising word vectors is a bit tricky becuase the vectors we are using happen to have 300 dimensions, and we as human beings are most comfortable looking at 2D data (charts, graphs etc).\n\nSo lets covert our 300D data down to 2D data using [PCA](http://setosa.io/ev/principal-component-analysis/)!\n\nPCA will basically just project the data points down whilst trying to keep the relative distances between data points the same i.e if the distance between `cat` and `boat` is more than the distance between `cat` and `dog` in 300 dimensions then the distance between `cat` and `boat` will be more than the distance between `cat` and `dog` in 2 dimensions (*or atleast PCA will work to try and make that happen*).\n\n### Play around with adding words to the `words` list and see where they end up"},{"metadata":{"_cell_guid":"c4697863-65bf-45c3-afb0-b0966b4a4354","_uuid":"f024d1f415e2fc883292623207eee73cd3815ed3","trusted":false,"collapsed":true},"cell_type":"code","source":"# import the PCA module from sklearn\nfrom sklearn.decomposition import PCA\n\n# this is just making sure we have loaded in our word vectors\nif 'nlp' not in locals():\n    nlp = spacy.load('en_core_web_lg')\n\ndef get_word_vectors(words):\n    # converts a list of words into their word vectors\n    return [nlp(word).vector for word in words]\n\nwords = ['car', 'truck', 'dragon', 'data', 'horse', 'fish' , 'lion']\n\n# intialise pca model and tell it to project data down onto 2 dimensions\npca = PCA(n_components=2)\n\n# fit the pca model to our 300D data, this will work out which is the best \n# way to project the data down that will best maintain the relative distances \n# between data points. It will store these intructioons on how to transform the data.\npca.fit(get_word_vectors(words))\n\n# Tell our (fitted) pca model to transform our 300D data down onto 2D using the \n# instructions it learnt during the fit phase.\nword_vecs_2d = pca.transform(get_word_vectors(words))\n\n# let's look at our new 2D word vectors\nword_vecs_2d","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"549229b2-deeb-445d-b038-815ce919d93a","_uuid":"f3f8bfd9744f43f6aecf9dedbc4044a19c88a2c6","trusted":false,"collapsed":true},"cell_type":"code","source":"# create a nice big plot \nplt.figure(figsize=(20,15))\n\n# plot the scatter plot of where the words will be\nplt.scatter(word_vecs_2d[:,0], word_vecs_2d[:,1])\n\n# for each word and coordinate pair: draw the text on the plot\nfor word, coord in zip(words, word_vecs_2d):\n    x, y = coord\n    plt.text(x, y, word, size= 15)\n\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ee4b83d3-40f6-4aee-afc0-9b92aabbb086","_uuid":"9cc61eddd2448e4bddc9a3acf24d6b8c7bc04741"},"cell_type":"markdown","source":"---\n\n# Let's build an article recommendation system\n\nAs you've probably seen on plenty of media sites, they love trying to recommend you what you should be reading/watching next in order to keep you on their site.\n\nIf you have loads of user data, you could come up with some sort of recommender system, however these systems will no perform so well when there is limited user interaction data e.g for newly publish media that no-one has viewed yet.\n\nSo lets build a system that will tell you what to read next based on the word vector similarity of the titles of articles.\n\n![related article](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/related_articles.png)"},{"metadata":{"_cell_guid":"fcf660bb-d997-4e37-8001-878011b2fd1e","_uuid":"780e9b4756cbb2538e5ee0dc7dde02f42361da2c"},"cell_type":"markdown","source":"## 1. Import the list of medium articles \n\nWe are going use pandas to read in the .csv, so the... \n\n**TASK** is to import pandas :\n\n```python\nimport pandas as pd\n```\n\nthen read in the csv into a Serise (that pandas for list ðŸ˜‰) and assign it to a varible named `medium_titles`:\n\n```python\npd.Series.from_csv('../input/medium_articles.csv').values\n```\n\nthe `.values` bit will get the titles out as a numpy array which works better with the functions we wrote earlier.\n\nthe `.shape` of your new `medium_titles` varible should be `(192,)`"},{"metadata":{"_cell_guid":"8239e8d2-41ce-430e-9478-3fc2fe6723af","_uuid":"f2728ac533a41a4ebe6897b683a705561a7975c6","trusted":false,"collapsed":true},"cell_type":"code","source":"# YOUR CODE GOES HERE \n\nimport pandas as pd\n\nmedium_titles = pd.Series.from_csv('../input/medium_articles.csv').values\n\nmedium_titles.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"75d72e74-312c-48e5-8149-a1187aca33b7","_uuid":"e9ec077f3418b68a0a166c791f0f4e97056203ad"},"cell_type":"markdown","source":"## 2. Covert our titles to title-vectors\n\nWe used a function earlier called `get_word_vectors()` which converted a list of text into a list of vectors.\n\n**TASK** : use `get_word_vectors()` to convert your `medium_titles` into vectors and assign them to a varible called `title_vectors`, or don't, your call"},{"metadata":{"_cell_guid":"213fa464-a4ef-488b-899c-d7e58a515e36","_uuid":"4dec85bfd1f36e3489a40169ffa12f0391f70323","collapsed":true,"trusted":false},"cell_type":"code","source":"# YOUR CODE GOES HERE \n\ntitle_vectors = get_word_vectors(medium_titles)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2076dd79-0b24-49b1-b750-bbeded227ccc","_uuid":"4233e88301ca308a4c1463657c704e7371089f95"},"cell_type":"markdown","source":"## 3. Build a Nearest Neighbors model that will do all of the similarity searching stuff for us ðŸ˜±\n\nYes, there is a really nice simple model called [nearest neighbors](https://en.wikipedia.org/wiki/Nearest_neighbor_search) that specilises in seraching for data points that are most similar to a given data point. You may also see it used in classification and regression models in the form of [K-Nearnest-neighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n\n![neighbors](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/nn_algo.png)\n\n**TASK** : import the `NearestNeighbors` module form sklearn (NOT **K**NearestNeighbors), it resides within the `.neighbors` package of sklearn"},{"metadata":{"_cell_guid":"37b9e3de-af28-4e9d-ba06-d936b5e2cbce","_uuid":"830dd6ab7fbf82384a3e1bd1c59fc2656f4be66e","collapsed":true,"trusted":false},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nfrom sklearn.neighbors import NearestNeighbors","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"de4eee70-0e11-4264-9871-3be47cbc88cf","_uuid":"6da81f58bcea084d09aff6b5bfd6154c034ac113"},"cell_type":"markdown","source":"**TASK** : create a new NearestNeighbors model and assign it to a varible called `neig_model`.\n\n```python\nNearestNeighbors(n_neighbors=NUMBER_OF_NEIGHBORS)\n```\n\nthe `n_neighbors` property defines the number of closest data points (neighbors) to retreive.\n\n![n_neighbors](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/n_neighbors.png)\n\nwe want use this model to find the closest 3 titles"},{"metadata":{"_cell_guid":"15427619-8796-4d24-9a51-fcadbf57b426","_uuid":"6d7897ec423e06d0ca45eb191d7baf391bc03623","collapsed":true,"trusted":false},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nneig_model = NearestNeighbors(n_neighbors=3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b7251bea-85f8-4f66-9f66-c520f0b30c47","_uuid":"ef7e93d1a8c1e658ea00ed92f6c370e6060e18d4"},"cell_type":"markdown","source":"**TASK** : fit the model to your `title_vectors`"},{"metadata":{"_cell_guid":"43ddb145-643e-4429-98bd-9180fcb64e84","_uuid":"59c74e2953e42361669f658bd97762b49b6829fa","trusted":false,"collapsed":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\nneig_model.fit(title_vectors)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6dfed179-cf51-444a-a588-7aeeecbfa7bc","_uuid":"2f8cada1f8f5cefe61153478983e7ee147e84522"},"cell_type":"markdown","source":"**TASK** : Find the titles that are most similare to the phrase `'I want a data job'`.\n\nYou query your model for closest neighbors by using the `.kneighbors()` function and passing it a **list** of vectors you want to search for, becuase we are only searching based on one vector, you should wrap your vector is square brackets e.g `.kneighbors([MY_VECTOR])`\n\n![neighbors](https://raw.githubusercontent.com/ZackAkil/nlp-using-word-vectors/master/images/nn_model.png)\n\nThe `.kneighbors()` function will return a list of distances and indices (see [docs](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors.kneighbors)).\n\nyou could just read the output of the `.kneighbors()` function and manually get the titles e.g `medium_titles[78]`\n\nor\n\nyou can store them by doing the following :\n\n```python\ndistances, indices = neig_model.kneighbors([YOUR_VECTOR])\n```\n\nThe indices are the indices of the data points you used to `fit` your model that are closest to the vector you passed in. \n\nThe distances are the distances to each of those points. \n\n**Useful numpy tip** : numpy has a function called [take](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.take.html) which will extract out the specific indices from a given list:\n\n```python\nsome_list = ['a', 'b', 'c', 'd', 'e', 'f']\n\nsome_indices = [2,5,1]\n\nnp.take(some_list, some_indices)\n\n>> ['c', 'f', 'b']\n```\n\n** you can check the completed noetboook if you get stuck **"},{"metadata":{"_cell_guid":"9c5a711a-caa6-44b2-8868-2046014369cc","_uuid":"0fc70c279d4b746b78fda771796f6559575e0d4e","trusted":false,"collapsed":true},"cell_type":"code","source":"# YOUR CODE GOES HERE\n\ndist, ind = neig_model.kneighbors([nlp('I want a data job').vector])\n\n# the indices list are wrapped in a list, that's why we need to use ind[0]\nnp.take(medium_titles, ind[0]) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3bc5f955-27d4-477b-8314-41afc09d4dfc","_uuid":"a892c6bf9deaa51913de664ced61328980b7c05d","trusted":false,"collapsed":true},"cell_type":"code","source":"# or manually type the indices in\nneig_model.kneighbors([nlp('I want a data job').vector])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2c4519ad-59e8-4ae5-bab4-97a73e51cbf9","_uuid":"b0f1f69d0200a446fe7c3f64ea16d5bfaf328365","trusted":false,"collapsed":true},"cell_type":"code","source":"medium_titles[73], medium_titles[62],  medium_titles[115]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4f66edd5-aaef-46da-b5c3-d3c8ee939648","_uuid":"d9a20d219e10c20f869246bd3679a102da827bb0"},"cell_type":"markdown","source":"## Extra task\n\nTweak you neigbors model to ignore stop words. \n\nSome tips:\n\n* The input data used to fit the model will need to be changed\n* The vector you pass to the `.kneighbors()` function will need changing too\n* We already have a function `remove_stop_words(text)` that removes the stop words from text"},{"metadata":{"_cell_guid":"02f711cd-b856-412a-a48e-f97f2b59f14b","_uuid":"70bb77884e72898bebeb25e5df0370c5754bd773"},"cell_type":"markdown","source":"## Congrats on finishing! ðŸš€ðŸš€ðŸš€\n\nYou should now have a some new ideas on how you can use word vectors.\n\nFor more advanced use cases of word vectors (deep learning, and how the vectors themselves are trained) I recommend looking at [Andrew Ng's deeplearning course on sequence models](https://www.coursera.org/learn/nlp-sequence-models)!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}